Okay i will go with hugging Face spaces. If needed, Fix or change code from the Below whole code (Dockerfile, app.py, Ldict.py, templates/index.html, requirements.txt)

Dockerfile
FROM python:3.12.2

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    NLTK_DATA=/root/nltk_data \
    FLASK_ENV=production \
    FLASK_APP=app.py \
    PORT=5003

# Set working directory in container
WORKDIR /app

# Copy the current directory contents into the container
COPY . .

# Install dependencies
RUN pip install -r requirements.txt

# Preload NLTK data
RUN python -m nltk.downloader punkt punkt_tab -d /root/nltk_data

# Expose the port the app runs on
EXPOSE 5003

# Run the Flask app
# CMD ["gunicorn", "app:app", "--bind", "0.0.0.0:5000"]
CMD ["python", "app.py"]


app.py
from flask import Flask, request, render_template, jsonify
import torch
from nltk.tokenize import word_tokenize
from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer, PegasusTokenizerFast, T5Tokenizer, T5ForConditionalGeneration, MBartForConditionalGeneration, MBart50TokenizerFast
from LDict import find_legal_terms, legal_terms_lower
import nltk
import re
import logging
logging.basicConfig(level=logging.ERROR)

nltk.download('punkt')
nltk.download('punkt_tab')

app = Flask(__name__)

device = "cuda" if torch.cuda.is_available() else "cpu"
# device = "mps" if torch.backends.mps.is_available() else "cpu"

#Method 1 model
pegasus_ckpt = "google/pegasus-cnn_dailymail"
tokenizer_pegasus = AutoTokenizer.from_pretrained(pegasus_ckpt)
model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(pegasus_ckpt).to(device)

# Method 2 model
port_tokenizer= AutoTokenizer.from_pretrained("stjiris/t5-portuguese-legal-summarization")
model_port = AutoModelForSeq2SeqLM.from_pretrained("stjiris/t5-portuguese-legal-summarization").to(device)

#paraphrase
t5_ckpt = "t5-base"
tokenizer_t5 = T5Tokenizer.from_pretrained(t5_ckpt)
model_t5 = T5ForConditionalGeneration.from_pretrained(t5_ckpt).to(device)

#Translation Model
mbart_ckpt = "facebook/mbart-large-50-one-to-many-mmt"
tokenizer_mbart = MBart50TokenizerFast.from_pretrained(mbart_ckpt,src_lang="en_XX")
model_mbart = MBartForConditionalGeneration.from_pretrained(mbart_ckpt).to(device)


def simplify_text(input_text):
    matches = find_legal_terms(input_text)
    tokens = word_tokenize(input_text)
    simplified_tokens = [f"{token} ({legal_terms_lower[token.lower()]})" if token.lower() in matches else token for token in tokens]
    return ' '.join(simplified_tokens)

def remove_parentheses(text):
    p1 = re.sub(r"[()]", "", text)
    p2 = re.sub(r"\s+", " ", p1).strip()
    p3 = re.sub(r"\b(the|a|an)\s+\1\b", r"\1", p2, flags=re.IGNORECASE)
    return p3

def summarize_text(text, method):
    if method == "method2":
        #Sumarry Model2
        inputs_legal = port_tokenizer(text, max_length=1024, truncation=True, return_tensors="pt")
        summary_ids_legal = model_port.generate(inputs_legal["input_ids"], max_length=250, num_beams=4, early_stopping=True)
        Summarized_method2 = port_tokenizer.decode(summary_ids_legal[0], skip_special_tokens=True)
        print("\n\n\n Summarized MEthod2",Summarized_method2, "\n\n\n\n")
        cleaned_summary2 = remove_parentheses(Summarized_method2)
        print("\n\n\n Cleaned Summarized MEthod2",cleaned_summary2, "\n\n\n\n")        
        #Paraphrase
        p_inputs = tokenizer_t5.encode(cleaned_summary2, return_tensors="pt", max_length=512, truncation=True)
        p_summary_ids = model_t5.generate(p_inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)
        method2 = tokenizer_t5.decode(p_summary_ids[0], skip_special_tokens=True)
        print("\n\n\n Summarized Paraphrased MEthod2",method2, "\n\n\n\n")
        return method2

    elif method == "method1":
        summarization_pipeline = pipeline('summarization', model=model_pegasus, tokenizer=tokenizer_pegasus, device=0 if device == "cuda" else -1)
        method1 = summarization_pipeline(text, max_length=100, min_length=30, truncation=True)[0]['summary_text']
        print("\n\n\n Summarized MEthod1",method1, "\n\n\n\n")                 
        cleaned_summary1 = remove_parentheses(method1)
        print("\n\n\n Summarized Cleaned MEthod1",cleaned_summary1, "\n\n\n\n")                
        return cleaned_summary1


def translate_to_hindi(text):
    inputs = tokenizer_mbart([text], return_tensors="pt", padding=True, truncation=True)
    translated_tokens = model_mbart.generate(**inputs, forced_bos_token_id=tokenizer_mbart.lang_code_to_id["hi_IN"])
    
    # Select the first sequence from the generated tokens
    translation = tokenizer_mbart.decode(translated_tokens[0], skip_special_tokens=True)  
    return translation

@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        try:
            input_text = request.form['input_text']
            logging.info(f"Received data for translation: {input_text}")  # Log incoming data
            method = request.form['method']
            
            simplified_text = simplify_text(input_text)
            logging.info(f"Received data for translation: {simplified_text}")
            summarized_text = summarize_text(simplified_text, method)
            logging.info(f"Received data for translation: {summarized_text}")

            return jsonify({
                "summarized_text": summarized_text,
            })
        except Exception as e:
            logging.error(f"Error occurred: {e}", exc_info=True)
            return jsonify({"error": str(e)}), 500
    return render_template('index.html')

@app.route('/translate', methods=['POST'])
def translate():
    try:
        data = request.get_json()
        logging.info(f"Received data for translation: {data}")  # Log incoming data
        text = data['text']
        translated_text = translate_to_hindi(text)

        return jsonify({
            "translated_text": translated_text
        })
    except Exception as e:
        logging.error(f"Error occurred during translation: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500


if __name__ == '__main__':
    app.run(port=5003)
    

Ldict.py
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
import re


legal_terms = {
    "Abandonment": "giving up a legal right.",
    "Abatement": "cancelling a writ or action; stopping a nuisance; reducing the payments to creditors in proportion, if there is not enough money to pay them in full; or reducing the bequests in a will, in proportion, when there is not enough money to pay them in full.",
    "Abduction": "taking someone away by force.", }
legal_terms_lower = {k.lower(): v.lower() for k, v in legal_terms.items()}

# Preprocessing functions
def preprocess(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text

def find_legal_terms(input_text):
    tokens = word_tokenize(preprocess(input_text))
    bigrams = [' '.join(ngram) for ngram in ngrams(tokens, 2)]
    trigrams = [' '.join(ngram) for ngram in ngrams(tokens, 3)]
    matches = set()

    for token in tokens + bigrams + trigrams:
        if token in legal_terms_lower:
            matches.add(token)
    return matches

templates/index.html
 <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NLP Legal Document Processor</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css">
    <style>
        body {
            background: linear-gradient(to bottom, royalblue, black);
            color: white;
            font-family: Arial, sans-serif;
            margin-top: 140px;
            margin-bottom: 310px;
        }
        h1 {
            margin-bottom: 20px;
        }
        .btn-primary, .btn-success {
            width: 100%;
        }
        #loading {
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container mt-5">
        <h1 class="text-center">NLP Machine Translation for Legal Docs</h1>
        <form method="POST" action="/" id="nlp-form">
            <div class="mb-3">
                <label for="inputText" class="form-label">Enter Legal Text</label>
                <textarea class="form-control" id="inputText" name="input_text" rows="6" required></textarea>
            </div>
            <div class="mb-3">
                <label for="method" class="form-label">Choose Summarization Method</label>
                <select class="form-select" id="method" name="method">
                    <option value="method1">Method 1</option>
                    <option value="method2">Method 2</option>
                </select>
            </div>
            <div id="loading" class="text-center text-warning" style="display: none;">Processing... Please wait.. It may take few minutes</div>
            <button type="button" class="btn btn-primary" id="processButton" onclick="processText()">Summarize</button>
        </form>

        <div id="result" class="mt-5"></div>
        <button type="button" class="btn btn-success mt-3" id="translateButton" style="display: none;" onclick="translateText()">Translate to Hindi</button>

    </div>

    <script>
        async function processText() {
            document.getElementById('loading').style.display = 'block';
            document.getElementById('result').innerHTML = '';
            document.getElementById('translateButton').style.display = 'none';

            const formData = new FormData(document.getElementById('nlp-form'));
            try {
                const response = await fetch('/', { method: 'POST', body: formData });
                const result = await response.json();

                if (result.error) throw new Error(result.error);

                document.getElementById('result').innerHTML = `
                    <h3>Summarized Text:</h3>
                    <p>${result.summarized_text}</p>
                `;
                document.getElementById('translateButton').style.display = 'block';
            } catch (error) {
                document.getElementById('result').innerHTML = `<p class="text-danger">Error: ${error.message}</p>`;
            } finally {
                document.getElementById('loading').style.display = 'none';
            }
        }

        async function translateText() {
            document.getElementById('loading').style.display = 'block';
            const summarizedText = document.querySelector('#result p').textContent;

            try {
                const response = await fetch('/translate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: summarizedText })
                });
                const result = await response.json();

                if (result.error) throw new Error(result.error);

                document.getElementById('result').innerHTML += `
                    <h3>Translated Text (Hindi):</h3>
                    <p>${result.translated_text}</p>
                `;
                document.getElementById('translateButton').style.display = 'none';
            } catch (error) {
                document.getElementById('result').innerHTML += `<p class="text-danger">Error: ${error.message}</p>`;
            } finally {
                document.getElementById('loading').style.display = 'none';
            }
        }
    </script>
</body>
</html>

requirements.txt
flask == 3.1.0
englisttohindi == 4.1.0
torch == 2.2.1
rouge_score == 0.1.2
transformers == 4.47.1
sentencepiece == 0.2.0
nltk == 3.9.1
sacrebleu == 2.5.1
gunicorn == 23.0.0
protobuf == 5.29.3
numpy == 1.26.0